{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21f47c09",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set cố định random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc94ff",
   "metadata": {},
   "source": [
    "# Add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.read_csv('review-data/positive_data.csv')\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c386aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nev_df = pd.read_csv('review-data/nevgative_data.csv')\n",
    "nev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9b611",
   "metadata": {},
   "source": [
    "> Đếm số giá trị Pos/ Nev?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nev_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a6e72",
   "metadata": {},
   "source": [
    "> Một số trường hợp class của sample có tỉ lệ quá khác biệt ảnh hưởng đến chất lượng mô hình. Vì vậy nên sử dụng phương thức chọn mẫu `DataFrame.sample()` để cho số lượng mẫu = nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b064a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df_sampled = pos_df.sample(n=len(nev_df), random_state=42) # Lấy mẫu ngẫu nhiên từ pos_df để có số lượng bằng với nev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b916f",
   "metadata": {},
   "source": [
    "> Kết hợp dữ liệu positive và negative vào cùng 1 DataFrame bằng `pandas.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a71f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.concat([pos_df_sampled, nev_df])\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xem du lieu moi nhat\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea13461",
   "metadata": {},
   "source": [
    "> Để phân phối lại các sample pos/nev trong df, sử dụng phương thức `DataFrame.sample`\n",
    "\n",
    "> Ở đây chọn `frac=1` để chọn **tất cả** các sample trong df với thứ tự ngẫu nhiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)  # Trộn dữ liệu\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba3b56f",
   "metadata": {},
   "source": [
    "> Đầu ra của mô hình phân loại 2 lớp (**binary classification**) là giá trị 0 hoặc 1 => Vì vậy cần `chuyển -1 (nev) -> 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e289d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame.replace\n",
    "df['label']= df['label'].replace({-1:0})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db991074",
   "metadata": {},
   "source": [
    "# Chia tập train:test\n",
    "- Sử dụng thuộc tính `values` của Pandas series để lấy các giá trị dưới dạng **numpy ndarray**\n",
    "- Các dữ liệu dung để train và test nên được chuyển sang `ndarray` để phù hợp với các hàm tính toán trong ML và DL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65657ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Review'].values\n",
    "y = df['Label'].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9bccb1",
   "metadata": {},
   "source": [
    "> Sử dụng hàm `train_test_split` để chia tập train:test **(tỉ lệ 8:2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc4cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# doi kieu du lieu ve numpy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d67e9",
   "metadata": {},
   "source": [
    "# Tokenize dữ liệu train - test\n",
    "Vận dụng các kiến thức tokenizing và padding ở buổi trước để xử lý dữ liệu chữ.\\\n",
    "Nhắc lại các bước xử lý:\n",
    "1. Chọn kích thước từ điển\n",
    "2. Chọn độ dài lớn nhất của một chuỗi (sequence)\n",
    "3. Tạo Tokenizer và fit Tokenizer (trên văn bản của tập train)\n",
    "4. Sử dụng Tokenizer đã huấn luyện để tạo tokens\n",
    "5. Sử dụng padding và truncating để các chuỗi có độ dài bằng nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30012eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b23116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chọn kích thước từ điển là 10000\n",
    "# độ dài lớn nhất của 1 bình luận 400 tokens\n",
    "vocab_size = 10000\n",
    "max_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo tokenizer và fit\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train) # đánh so\n",
    "# sử dụng tokenizer để train trên tập train\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post') # đệm câu nếu thiếu/ cắt câu nếu dư"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f57dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sử dụng tokenizer để fit trên tập test\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca4fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of train dataset:\", len(X_train_pad))\n",
    "print(\"Length of test dataset:\", len(X_test_pad))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
