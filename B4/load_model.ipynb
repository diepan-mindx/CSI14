{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7e40be",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423ba30c",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb25726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "DATA_DIR = os.path.join(\n",
    "    path,\n",
    "    \"asl_alphabet_train\",\n",
    "    \"asl_alphabet_train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e820d4",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model(\"asl_alphabet_model.h5\")\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaaceec",
   "metadata": {},
   "source": [
    "# Chuẩn bị lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4469b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b058359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuan bi label (chu cai)\n",
    "# cắt tập train : validation + scale ảnh\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # chuyen doi gia tri [0, 255] ve [0, 1]\n",
    "    validation_split=0.2 # chia du lieu thanh 80% train va 20% validation\n",
    ")\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training' # chi dinh lay tap train\n",
    ")\n",
    "class_names = train_data.class_indices\n",
    "class_names = dict((v, k) for k, v in class_names.items())  # dao nguoc key va value\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# đi qua tất cả file trong thư mục test\n",
    "test_images = glob(os.path.join(path,  \"asl_alphabet_train\", \"asl_alphabet_train\", \"nothing/**\"))\n",
    "test_images[10:15]  # in ra 5 file đầu tiên"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063cec3c",
   "metadata": {},
   "source": [
    "# Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec182db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve hinh anh \n",
    "import cv2\n",
    "test_img_path = test_images[12]\n",
    "img = cv2.imread(test_img_path)\n",
    "plt.rcParams['figure.figsize'] = [5, 5]\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(test_img_path.split(\"\\\\\")[-1])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43413de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# du doan hinh\n",
    "img = image.load_img(test_img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # scale anh\n",
    "img_array = np.expand_dims(img_array, axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce38277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# du doan hih\n",
    "prediction = loaded_model.predict(img_array)\n",
    "predicted_probs = tf.nn.softmax(prediction[0])\n",
    "\n",
    "# Get top 2 predictions\n",
    "top_2_indices = np.argsort(predicted_probs)[-2:]\n",
    "top_1_prob = predicted_probs[top_2_indices[1]]\n",
    "top_2_prob = predicted_probs[top_2_indices[0]]\n",
    "\n",
    "PROBABILITY_GAP = 0.3  # top prediction should be at least 30% higher\n",
    "\n",
    "if top_1_prob < 0.6 or (top_1_prob - top_2_prob) < PROBABILITY_GAP:\n",
    "    print(\"ERROR: Ambiguous or invalid image!\")\n",
    "    print(f\"Top prediction: {top_1_prob:.2%}, Second: {top_2_prob:.2%}\")\n",
    "else:\n",
    "    predicted_label = class_names[top_2_indices[1]]\n",
    "    print(f'Predicted label: {predicted_label} (Confidence: {top_1_prob:.2%})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
