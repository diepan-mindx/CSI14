{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad76fa20",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "import os\n",
    "\n",
    "DATA_DIR = os.path.join(\n",
    "    path,\n",
    "    \"asl_alphabet_train\",\n",
    "    \"asl_alphabet_train\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee629ac",
   "metadata": {},
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f000a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4fbd8",
   "metadata": {},
   "source": [
    "# Chuan hoa du lieu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30d189",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128 # bn hinh 1 lan chay epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be59d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cai thien datagen\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd85cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training' # chi dinh lay tap train\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation' # chi dinh lay tap validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f257b5",
   "metadata": {},
   "source": [
    "# Khai bao mo hinh - fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79050737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BatchNormalization and stronger regularization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),  # increase dropout\n",
    "    Dense(29)  # no activation here, use from_logits=True\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e595aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huan luyen\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=10,\n",
    "    validation_data=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167097f",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbf0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('asl_alphabet_model.h5') # .h5: dung de load lai va du doan cho sau nay\n",
    "print('Saved model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49bfec",
   "metadata": {},
   "source": [
    "# Danh gia mo hinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(val_data)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd911f3e",
   "metadata": {},
   "source": [
    "# Du doan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mo hinh \n",
    "loaded_model = keras.models.load_model('asl_alphabet_model.h5')\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuan bi label (chu cai)\n",
    "class_names = list(train_data.class_indices.keys())\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c8499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1 hinh de xu ly\n",
    "img_dir = os.path.join(path, \"asl_alphabet_train\", \"asl_alphabet_train\", \"M\")  # duong dan den thu muc chua hinh\n",
    "# Get first image file\n",
    "img_file = os.listdir(img_dir)[0]\n",
    "img_path = os.path.join(img_dir, img_file) # duong dan den hinh can du doan\n",
    "# img_path = input(\"Enter the path of the image to predict: \")\n",
    "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0  # scale anh\n",
    "img_array = np.expand_dims(img_array, axis=0)  # them kich thuoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd70234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# du doan\n",
    "prediction = loaded_model.predict(img_array)\n",
    "predicted_index = np.argmax(prediction)\n",
    "predicted_label = class_names[predicted_index] # map index -> label\n",
    "\n",
    "# print % cac lop du doan\n",
    "print(prediction)\n",
    "print(f'Predicted label: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
